{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'  #默认为'last'\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "from numpy import linalg\n",
    "np.set_printoptions(threshold=np.inf, precision=2, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 299s 26us/step\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 0.2990 - accuracy: 0.9125\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 3s 51us/sample - loss: 0.1490 - accuracy: 0.9552\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 3s 51us/sample - loss: 0.1098 - accuracy: 0.9667\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 3s 51us/sample - loss: 0.0915 - accuracy: 0.9717\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.0762 - accuracy: 0.9760\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f7ed35e4c8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 - 1s - loss: 0.0742 - accuracy: 0.9757\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07416248116875067, 0.9757]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 2, 3])>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tf.int32"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 2, 3])>>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant([1,2,3])\n",
    "a\n",
    "a.shape\n",
    "a.dtype\n",
    "a.numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 3), dtype=float32, numpy=\n",
       "array([[1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.ones((4,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[-0.61,  1.02,  0.12],\n",
       "       [ 1.2 , -0.81, -0.36],\n",
       "       [ 0.85,  1.25, -0.23]], dtype=float32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.normal(shape=(3,3),mean=0,stddev=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[4.62, 2.68, 8.97],\n",
       "       [7.3 , 6.13, 0.05],\n",
       "       [1.63, 9.63, 1.77]], dtype=float32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.uniform(shape=(3,3),minval=0,maxval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[0.2 , 0.65, 0.31],\n",
       "       [0.34, 0.97, 0.94],\n",
       "       [0.72, 0.66, 0.65]], dtype=float32)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.uniform(shape=(3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(4,) dtype=int32, numpy=array([1, 1, 5, 1])>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tf.random_normal([1,1,5,1])\n",
    "tf.Variable([1,1,5,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function conv2d_v2 in module tensorflow.python.ops.nn_ops:\n",
      "\n",
      "conv2d_v2(input, filters, strides, padding, data_format='NHWC', dilations=None, name=None)\n",
      "    Computes a 2-D convolution given 4-D `input` and `filters` tensors.\n",
      "    \n",
      "    Given an input tensor of shape `[batch, in_height, in_width, in_channels]`\n",
      "    and a filter / kernel tensor of shape\n",
      "    `[filter_height, filter_width, in_channels, out_channels]`, this op\n",
      "    performs the following:\n",
      "    \n",
      "    1. Flattens the filter to a 2-D matrix with shape\n",
      "       `[filter_height * filter_width * in_channels, output_channels]`.\n",
      "    2. Extracts image patches from the input tensor to form a *virtual*\n",
      "       tensor of shape `[batch, out_height, out_width,\n",
      "       filter_height * filter_width * in_channels]`.\n",
      "    3. For each patch, right-multiplies the filter matrix and the image patch\n",
      "       vector.\n",
      "    \n",
      "    In detail, with the default NHWC format,\n",
      "    \n",
      "        output[b, i, j, k] =\n",
      "            sum_{di, dj, q} input[b, strides[1] * i + di, strides[2] * j + dj, q] *\n",
      "                            filter[di, dj, q, k]\n",
      "    \n",
      "    Must have `strides[0] = strides[3] = 1`.  For the most common case of the same\n",
      "    horizontal and vertices strides, `strides = [1, stride, stride, 1]`.\n",
      "    \n",
      "    Args:\n",
      "      input: A `Tensor`. Must be one of the following types:\n",
      "        `half`, `bfloat16`, `float32`, `float64`.\n",
      "        A 4-D tensor. The dimension order is interpreted according to the value\n",
      "        of `data_format`, see below for details.\n",
      "      filters: A `Tensor`. Must have the same type as `input`.\n",
      "        A 4-D tensor of shape\n",
      "        `[filter_height, filter_width, in_channels, out_channels]`\n",
      "      strides: An int or list of `ints` that has length `1`, `2` or `4`.  The\n",
      "        stride of the sliding window for each dimension of `input`. If a single\n",
      "        value is given it is replicated in the `H` and `W` dimension. By default\n",
      "        the `N` and `C` dimensions are set to 1. The dimension order is determined\n",
      "        by the value of `data_format`, see below for details.\n",
      "      padding: Either the `string` `\"SAME\"` or `\"VALID\"` indicating the type of\n",
      "        padding algorithm to use, or a list indicating the explicit paddings at\n",
      "        the start and end of each dimension. When explicit padding is used and\n",
      "        data_format is `\"NHWC\"`, this should be in the form `[[0, 0], [pad_top,\n",
      "        pad_bottom], [pad_left, pad_right], [0, 0]]`. When explicit padding used\n",
      "        and data_format is `\"NCHW\"`, this should be in the form `[[0, 0], [0, 0],\n",
      "        [pad_top, pad_bottom], [pad_left, pad_right]]`.\n",
      "      data_format: An optional `string` from: `\"NHWC\", \"NCHW\"`.\n",
      "        Defaults to `\"NHWC\"`.\n",
      "        Specify the data format of the input and output data. With the\n",
      "        default format \"NHWC\", the data is stored in the order of:\n",
      "            [batch, height, width, channels].\n",
      "        Alternatively, the format could be \"NCHW\", the data storage order of:\n",
      "            [batch, channels, height, width].\n",
      "      dilations: An int or list of `ints` that has length `1`, `2` or `4`,\n",
      "        defaults to 1. The dilation factor for each dimension of`input`. If a\n",
      "        single value is given it is replicated in the `H` and `W` dimension. By\n",
      "        default the `N` and `C` dimensions are set to 1. If set to k > 1, there\n",
      "        will be k-1 skipped cells between each filter element on that dimension.\n",
      "        The dimension order is determined by the value of `data_format`, see above\n",
      "        for details. Dilations in the batch and depth dimensions if a 4-d tensor\n",
      "        must be 1.\n",
      "      name: A name for the operation (optional).\n",
      "    \n",
      "    Returns:\n",
      "      A `Tensor`. Has the same type as `input`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.nn.conv2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(1, 5, 5, 1) dtype=float32, numpy=\n",
       "array([[[[1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]],\n",
       "\n",
       "        [[1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]],\n",
       "\n",
       "        [[1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]],\n",
       "\n",
       "        [[1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]],\n",
       "\n",
       "        [[1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 2, 1, 1) dtype=float32, numpy=\n",
       "array([[[[-1.]],\n",
       "\n",
       "        [[ 0.]]],\n",
       "\n",
       "\n",
       "       [[[ 0.]],\n",
       "\n",
       "        [[-1.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3, 3, 1), dtype=float32, numpy=\n",
       "array([[[[-2.],\n",
       "         [-2.],\n",
       "         [-1.]],\n",
       "\n",
       "        [[-2.],\n",
       "         [-2.],\n",
       "         [-1.]],\n",
       "\n",
       "        [[-1.],\n",
       "         [-1.],\n",
       "         [-1.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input2 = tf.Variable(tf.constant(1.0, shape=[1, 5, 5, 1]))\n",
    "filter2 = tf.Variable(tf.constant([-1.0, 0, 0, -1], shape=[2, 2, 1, 1]))\n",
    "op2 = tf.nn.conv2d(input2, filter2, strides=[1, 2, 2, 1], padding='SAME')\n",
    "input2\n",
    "filter2\n",
    "op2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1, 5, 5), dtype=float32, numpy=\n",
       "array([[[[4., 6., 6., 6., 4.],\n",
       "         [6., 9., 9., 9., 6.],\n",
       "         [6., 9., 9., 9., 6.],\n",
       "         [6., 9., 9., 9., 6.],\n",
       "         [4., 6., 6., 6., 4.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input1 = tf.Variable(tf.constant(1.0, shape=[1, 1, 5, 5]))\n",
    "filter1 = tf.Variable(tf.constant(1.0, shape=[3, 3, 1, 1]))\n",
    "# tf.nn.conv2d(input, filters, strides, padding, data_format='NHWC', dilations=None, name=None)\n",
    "# tf.nn.conv2d(input=input1,filters=filter1,strides=1,padding=\"VALID\")\n",
    "tf.nn.conv2d(input=input1,filters=filter1,strides=[1,1,1,1],padding=\"SAME\",data_format=\"NCHW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 5, 5, 1), dtype=float32, numpy=\n",
       "array([[[[1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]],\n",
       "\n",
       "        [[1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]],\n",
       "\n",
       "        [[1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]],\n",
       "\n",
       "        [[1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]],\n",
       "\n",
       "        [[1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 1, 1), dtype=float32, numpy=\n",
       "array([[[[1.]],\n",
       "\n",
       "        [[2.]]],\n",
       "\n",
       "\n",
       "       [[[3.]],\n",
       "\n",
       "        [[4.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 1, 1), dtype=float32, numpy=\n",
       "array([[[[3.]],\n",
       "\n",
       "        [[3.]]],\n",
       "\n",
       "\n",
       "       [[[1.]],\n",
       "\n",
       "        [[1.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant([1,2,3,4],dtype=tf.float32)\n",
    "tf.reshape(a,[2,2,1,-1])\n",
    "tf.reshape(tf.constant([3,3,1,1],dtype=tf.float32),[2,2,1,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 1, 1), dtype=float32, numpy=\n",
       "array([[[[1.]],\n",
       "\n",
       "        [[2.]]],\n",
       "\n",
       "\n",
       "       [[[3.]],\n",
       "\n",
       "        [[4.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter1 = tf.constant([[[[1]],\n",
    "  [[2]]],\n",
    "\n",
    " [[[ 3]],\n",
    "  [[4]]]],dtype=tf.float32)\n",
    "filter1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function reshape in module tensorflow.python.ops.array_ops:\n",
      "\n",
      "reshape(tensor, shape, name=None)\n",
      "    Reshapes a tensor.\n",
      "    \n",
      "    Given `tensor`, this operation returns a new `tf.Tensor` that has the same\n",
      "    values as `tensor` in the same order, except with a new shape given by\n",
      "    `shape`.\n",
      "    \n",
      "    >>> t1 = [[1, 2, 3],\n",
      "    ...       [4, 5, 6]]\n",
      "    >>> print(tf.shape(t1).numpy())\n",
      "    [2 3]\n",
      "    >>> t2 = tf.reshape(t1, [6])\n",
      "    >>> t2\n",
      "    <tf.Tensor: shape=(6,), dtype=int32,\n",
      "      numpy=array([1, 2, 3, 4, 5, 6], dtype=int32)>\n",
      "    >>> tf.reshape(t2, [3, 2])\n",
      "    <tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
      "      array([[1, 2],\n",
      "             [3, 4],\n",
      "             [5, 6]], dtype=int32)>\n",
      "    \n",
      "    The `tf.reshape` does not change the order of or the total number of elements\n",
      "    in the tensor, and so it can reuse the underlying data buffer. This makes it\n",
      "    a fast operation independent of how big of a tensor it is operating on.\n",
      "    \n",
      "    >>> tf.reshape([1, 2, 3], [2, 2])\n",
      "    Traceback (most recent call last):\n",
      "    ...\n",
      "    InvalidArgumentError: Input to reshape is a tensor with 3 values, but the\n",
      "    requested shape has 4\n",
      "    \n",
      "    To instead reorder the data to rearrange the dimensions of a tensor, see\n",
      "    `tf.transpose`.\n",
      "    \n",
      "    >>> t = [[1, 2, 3],\n",
      "    ...      [4, 5, 6]]\n",
      "    >>> tf.reshape(t, [3, 2]).numpy()\n",
      "    array([[1, 2],\n",
      "           [3, 4],\n",
      "           [5, 6]], dtype=int32)\n",
      "    >>> tf.transpose(t, perm=[1, 0]).numpy()\n",
      "    array([[1, 4],\n",
      "           [2, 5],\n",
      "           [3, 6]], dtype=int32)\n",
      "    \n",
      "    If one component of `shape` is the special value -1, the size of that\n",
      "    dimension is computed so that the total size remains constant.  In particular,\n",
      "    a `shape` of `[-1]` flattens into 1-D.  At most one component of `shape` can\n",
      "    be -1.\n",
      "    \n",
      "    >>> t = [[1, 2, 3],\n",
      "    ...      [4, 5, 6]]\n",
      "    >>> tf.reshape(t, [-1])\n",
      "    <tf.Tensor: shape=(6,), dtype=int32,\n",
      "      numpy=array([1, 2, 3, 4, 5, 6], dtype=int32)>\n",
      "    >>> tf.reshape(t, [3, -1])\n",
      "    <tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
      "      array([[1, 2],\n",
      "             [3, 4],\n",
      "             [5, 6]], dtype=int32)>\n",
      "    >>> tf.reshape(t, [-1, 2])\n",
      "    <tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
      "      array([[1, 2],\n",
      "             [3, 4],\n",
      "             [5, 6]], dtype=int32)>\n",
      "    \n",
      "    `tf.reshape(t, [])` reshapes a tensor `t` with one element to a scalar.\n",
      "    \n",
      "    >>> tf.reshape([7], []).numpy()\n",
      "    7\n",
      "    \n",
      "    More examples:\n",
      "    \n",
      "    >>> t = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "    >>> print(tf.shape(t).numpy())\n",
      "    [9]\n",
      "    >>> tf.reshape(t, [3, 3])\n",
      "    <tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
      "      array([[1, 2, 3],\n",
      "             [4, 5, 6],\n",
      "             [7, 8, 9]], dtype=int32)>\n",
      "    \n",
      "    >>> t = [[[1, 1], [2, 2]],\n",
      "    ...      [[3, 3], [4, 4]]]\n",
      "    >>> print(tf.shape(t).numpy())\n",
      "    [2 2 2]\n",
      "    >>> tf.reshape(t, [2, 4])\n",
      "    <tf.Tensor: shape=(2, 4), dtype=int32, numpy=\n",
      "      array([[1, 1, 2, 2],\n",
      "             [3, 3, 4, 4]], dtype=int32)>\n",
      "    \n",
      "    >>> t = [[[1, 1, 1],\n",
      "    ...       [2, 2, 2]],\n",
      "    ...      [[3, 3, 3],\n",
      "    ...       [4, 4, 4]],\n",
      "    ...      [[5, 5, 5],\n",
      "    ...       [6, 6, 6]]]\n",
      "    >>> print(tf.shape(t).numpy())\n",
      "    [3 2 3]\n",
      "    >>> # Pass '[-1]' to flatten 't'.\n",
      "    >>> tf.reshape(t, [-1])\n",
      "    <tf.Tensor: shape=(18,), dtype=int32,\n",
      "      numpy=array([1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6],\n",
      "      dtype=int32)>\n",
      "    >>> # -- Using -1 to infer the shape --\n",
      "    >>> # Here -1 is inferred to be 9:\n",
      "    >>> tf.reshape(t, [2, -1])\n",
      "    <tf.Tensor: shape=(2, 9), dtype=int32, numpy=\n",
      "      array([[1, 1, 1, 2, 2, 2, 3, 3, 3],\n",
      "             [4, 4, 4, 5, 5, 5, 6, 6, 6]], dtype=int32)>\n",
      "    >>> # -1 is inferred to be 2:\n",
      "    >>> tf.reshape(t, [-1, 9])\n",
      "    <tf.Tensor: shape=(2, 9), dtype=int32, numpy=\n",
      "      array([[1, 1, 1, 2, 2, 2, 3, 3, 3],\n",
      "             [4, 4, 4, 5, 5, 5, 6, 6, 6]], dtype=int32)>\n",
      "    >>> # -1 is inferred to be 3:\n",
      "    >>> tf.reshape(t, [ 2, -1, 3])\n",
      "    <tf.Tensor: shape=(2, 3, 3), dtype=int32, numpy=\n",
      "      array([[[1, 1, 1],\n",
      "              [2, 2, 2],\n",
      "              [3, 3, 3]],\n",
      "             [[4, 4, 4],\n",
      "              [5, 5, 5],\n",
      "              [6, 6, 6]]], dtype=int32)>\n",
      "    \n",
      "    Args:\n",
      "      tensor: A `Tensor`.\n",
      "      shape: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "        Defines the shape of the output tensor.\n",
      "      name: Optional string. A name for the operation.\n",
      "    \n",
      "    Returns:\n",
      "      A `Tensor`. Has the same type as `tensor`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.reshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
