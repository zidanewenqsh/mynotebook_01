{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'  #默认为'last'\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "from numpy import linalg\n",
    "np.set_printoptions(threshold=np.inf, precision=2, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# torch.sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 3.],\n",
       "        [4., 0., 5.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = torch.LongTensor([[0, 1, 1], [2, 0, 2]])\n",
    "v = torch.FloatTensor([3, 4, 5])\n",
    "torch.sparse.FloatTensor(i, v, torch.Size([2,3])).to_dense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 3.],\n",
       "        [4., 0., 5.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = torch.LongTensor([[0, 2], [1, 0], [1, 2]])\n",
    "v = torch.FloatTensor([3, 4, 5])\n",
    "torch.sparse.FloatTensor(i.t(), v, torch.Size([2, 3])).to_dense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 4]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1., 3.],\n",
       "        [5., 7.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor(indices=tensor([[2, 4]]),\n",
       "       values=tensor([[1., 3.],\n",
       "                      [5., 7.]]),\n",
       "       size=(5, 2), nnz=2, layout=torch.sparse_coo)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [1., 3.],\n",
       "        [0., 0.],\n",
       "        [5., 7.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = torch.LongTensor([[2, 4]])\n",
    "i\n",
    "v = torch.FloatTensor([[1, 3], [5, 7]])\n",
    "v\n",
    "torch.sparse.FloatTensor(i, v)\n",
    "torch.sparse.FloatTensor(i, v).to_dense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(indices=tensor([[0, 0, 0, 1, 1, 1],\n",
       "                       [0, 1, 2, 0, 1, 2]]),\n",
       "       values=tensor([ 2.0876, -0.3764,  0.4160, -0.5974, -1.8790,  1.1513]),\n",
       "       size=(2, 3), nnz=6, layout=torch.sparse_coo, requires_grad=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.0876, -0.3764,  0.4160],\n",
       "        [-0.5974, -1.8790,  1.1513]], grad_fn=<ToDenseBackward>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.1082,  0.7027],\n",
       "        [ 1.6664,  0.8173],\n",
       "        [-1.6953,  0.5092]], requires_grad=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.0686,  1.3711],\n",
       "        [-6.3424, -1.3692]], grad_fn=<SparseAddmmBackward>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor(indices=tensor([[0, 0, 0, 1, 1, 1],\n",
       "                       [0, 1, 2, 0, 1, 2]]),\n",
       "       values=tensor([ 2.8109,  2.4837, -1.1860,  2.8109,  2.4837, -1.1860]),\n",
       "       size=(2, 3), nnz=6, layout=torch.sparse_coo)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(2, 3).to_sparse().requires_grad_(True)\n",
    "a\n",
    "a.to_dense()\n",
    "# tensor(indices=tensor([[0, 0, 0, 1, 1, 1],\n",
    "#                        [0, 1, 2, 0, 1, 2]]),\n",
    "#        values=tensor([ 1.5901,  0.0183, -0.6146,  1.8061, -0.0112,  0.6302]),\n",
    "#        size=(2, 3), nnz=6, layout=torch.sparse_coo, requires_grad=True)\n",
    "\n",
    "b = torch.randn(3, 2, requires_grad=True)\n",
    "b\n",
    "# tensor([[-0.6479,  0.7874],\n",
    "#         [-1.2056,  0.5641],\n",
    "#         [-1.1716, -0.9923]], requires_grad=True)\n",
    "\n",
    "y = torch.sparse.mm(a, b)\n",
    "y\n",
    "# tensor([[-0.3323,  1.8723],\n",
    "#         [-1.8951,  0.7904]], grad_fn=<SparseAddmmBackward>)\n",
    "y.sum().backward()\n",
    "a.grad\n",
    "# tensor(indices=tensor([[0, 0, 0, 1, 1, 1],\n",
    "#                        [0, 1, 2, 0, 1, 2]]),\n",
    "#        values=tensor([ 0.1394, -0.6415, -2.1639,  0.1394, -0.6415, -2.1639]),\n",
    "#        size=(2, 3), nnz=6, layout=torch.sparse_coo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# einsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.3010,  0.1340, -2.2113, -0.6608],\n",
       "        [ 0.7092,  0.0731, -1.2054, -0.3602],\n",
       "        [-0.5546, -0.0571,  0.9426,  0.2817],\n",
       "        [ 0.6613,  0.0681, -1.1240, -0.3359],\n",
       "        [ 0.6079,  0.0626, -1.0333, -0.3088]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6743,  0.2117, -0.1060],\n",
       "        [-5.9914,  2.7196, -8.2246]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.9479, -0.8942,  0.6105,  1.2177],\n",
       "         [ 5.1920, -2.0442,  3.7597,  0.2774]],\n",
       "\n",
       "        [[ 1.9755,  3.0665,  0.5966, -2.7625],\n",
       "         [-1.7776, -4.3762, -0.1269, -1.9066]],\n",
       "\n",
       "        [[ 1.1460,  1.0215, -0.8949,  1.3821],\n",
       "         [-0.1486, -1.9964,  1.4362, -0.9691]]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.5741,  0.7686, -1.5141])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9746, -1.4177, -1.3442],\n",
       "        [-0.2116,  0.5845,  0.7181],\n",
       "        [ 0.2219, -0.7531,  1.5207],\n",
       "        [-0.9117, -1.1787,  0.6000]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 5, 4])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(5)\n",
    "y = torch.randn(4)\n",
    "torch.einsum('i,j->ij', x, y)  # outer product\n",
    "# tensor([[-0.0570, -0.0286, -0.0231,  0.0197],\n",
    "#         [ 1.2616,  0.6335,  0.5113, -0.4351],\n",
    "#         [ 1.4452,  0.7257,  0.5857, -0.4984],\n",
    "#         [-0.4647, -0.2333, -0.1883,  0.1603],\n",
    "#         [-1.1130, -0.5588, -0.4510,  0.3838]])\n",
    "\n",
    "\n",
    "A = torch.randn(3,5,4)\n",
    "l = torch.randn(2,5)\n",
    "r = torch.randn(2,4)\n",
    "torch.einsum('bn,anm,bm->ba', l, A, r) # compare torch.nn.functional.bilinear\n",
    "# tensor([[-0.3430, -5.2405,  0.4494],\n",
    "#         [ 0.3311,  5.5201, -3.0356]])\n",
    "\n",
    "\n",
    "As = torch.randn(3,2,5)\n",
    "Bs = torch.randn(3,5,4)\n",
    "torch.einsum('bij,bjk->bik', As, Bs) # batch matrix multiplication\n",
    "# tensor([[[-1.0564, -1.5904,  3.2023,  3.1271],\n",
    "#          [-1.6706, -0.8097, -0.8025, -2.1183]],\n",
    "\n",
    "#         [[ 4.2239,  0.3107, -0.5756, -0.2354],\n",
    "#          [-1.4558, -0.3460,  1.5087, -0.8530]],\n",
    "\n",
    "#         [[ 2.8153,  1.8787, -4.3839, -1.2112],\n",
    "#          [ 0.3728, -2.1131,  0.0921,  0.8305]]])\n",
    "\n",
    "A = torch.randn(3, 3)\n",
    "torch.einsum('ii->i', A) # diagonal\n",
    "# tensor([-0.7825,  0.8291, -0.1936])\n",
    "\n",
    "A = torch.randn(4, 3, 3)\n",
    "torch.einsum('...ii->...i', A) # batch diagonal\n",
    "# tensor([[-1.0864,  0.7292,  0.0569],\n",
    "#         [-0.9725, -1.0270,  0.6493],\n",
    "#         [ 0.5832, -1.1716, -1.5084],\n",
    "#         [ 0.4041, -1.1690,  0.8570]])\n",
    "\n",
    "A = torch.randn(2, 3, 4, 5)\n",
    "torch.einsum('...ij->...ji', A).shape # batch permute\n",
    "# torch.Size([2, 3, 5, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11]],\n",
       "\n",
       "        [[12, 13, 14, 15],\n",
       "         [16, 17, 18, 19],\n",
       "         [20, 21, 22, 23]]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1.],\n",
       "         [1., 1.]],\n",
       "\n",
       "        [[1., 1.],\n",
       "         [1., 1.]],\n",
       "\n",
       "        [[1., 1.],\n",
       "         [1., 1.]]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 6.,  6.],\n",
       "          [ 6.,  6.]],\n",
       "\n",
       "         [[22., 22.],\n",
       "          [22., 22.]],\n",
       "\n",
       "         [[38., 38.],\n",
       "          [38., 38.]]],\n",
       "\n",
       "\n",
       "        [[[54., 54.],\n",
       "          [54., 54.]],\n",
       "\n",
       "         [[70., 70.],\n",
       "          [70., 70.]],\n",
       "\n",
       "         [[86., 86.],\n",
       "          [86., 86.]]]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 2, 2])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(24).reshape(2,3,4)\n",
    "b = torch.arange(12).reshape(3,2,2)\n",
    "b = torch.ones(3,2,2)\n",
    "a\n",
    "b\n",
    "# torch.einsum('bij,bjk', a, b）\n",
    "c = torch.einsum('ij...,jkl->ijkl', a, b)\n",
    "c\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.,  1.],\n",
       "          [ 2.,  3.],\n",
       "          [ 4.,  5.]],\n",
       "\n",
       "         [[ 6.,  7.],\n",
       "          [ 8.,  9.],\n",
       "          [10., 11.]]],\n",
       "\n",
       "\n",
       "        [[[12., 13.],\n",
       "          [14., 15.],\n",
       "          [16., 17.]],\n",
       "\n",
       "         [[18., 19.],\n",
       "          [20., 21.],\n",
       "          [22., 23.]]]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 2., 1., 2.],\n",
       "         [1., 2., 1., 2.],\n",
       "         [1., 2., 1., 2.]],\n",
       "\n",
       "        [[1., 2., 1., 2.],\n",
       "         [1., 2., 1., 2.],\n",
       "         [1., 2., 1., 2.]]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.,  2.,  1.,  2.],\n",
       "          [ 5., 10.,  5., 10.],\n",
       "          [ 9., 18.,  9., 18.]],\n",
       "\n",
       "         [[13., 26., 13., 26.],\n",
       "          [17., 34., 17., 34.],\n",
       "          [21., 42., 21., 42.]]],\n",
       "\n",
       "\n",
       "        [[[25., 50., 25., 50.],\n",
       "          [29., 58., 29., 58.],\n",
       "          [33., 66., 33., 66.]],\n",
       "\n",
       "         [[37., 74., 37., 74.],\n",
       "          [41., 82., 41., 82.],\n",
       "          [45., 90., 45., 90.]]]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 3, 4])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(24.).reshape(2,2,3,2)\n",
    "# b = torch.arange(12).reshape(3,2,2)\n",
    "b = torch.Tensor([1,2]).repeat(2, 3, 2)\n",
    "a\n",
    "b\n",
    "c = torch.einsum('bij...,bjk->bijk', a, b)\n",
    "# c = torch.einsum('ij,jk->ik', a, b)\n",
    "c\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function repeat:\n",
      "\n",
      "repeat(...) method of torch.Tensor instance\n",
      "    repeat(*sizes) -> Tensor\n",
      "    \n",
      "    Repeats this tensor along the specified dimensions.\n",
      "    \n",
      "    Unlike :meth:`~Tensor.expand`, this function copies the tensor's data.\n",
      "    \n",
      "    .. warning::\n",
      "    \n",
      "        :func:`torch.repeat` behaves differently from\n",
      "        `numpy.repeat <https://docs.scipy.org/doc/numpy/reference/generated/numpy.repeat.html>`_,\n",
      "        but is more similar to\n",
      "        `numpy.tile <https://docs.scipy.org/doc/numpy/reference/generated/numpy.tile.html>`_.\n",
      "        For the operator similar to `numpy.repeat`, see :func:`torch.repeat_interleave`.\n",
      "    \n",
      "    Args:\n",
      "        sizes (torch.Size or int...): The number of times to repeat this tensor along each\n",
      "            dimension\n",
      "    \n",
      "    Example::\n",
      "    \n",
      "        >>> x = torch.tensor([1, 2, 3])\n",
      "        >>> x.repeat(4, 2)\n",
      "        tensor([[ 1,  2,  3,  1,  2,  3],\n",
      "                [ 1,  2,  3,  1,  2,  3],\n",
      "                [ 1,  2,  3,  1,  2,  3],\n",
      "                [ 1,  2,  3,  1,  2,  3]])\n",
      "        >>> x.repeat(4, 2, 1).size()\n",
      "        torch.Size([4, 2, 3])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(a.repeat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
