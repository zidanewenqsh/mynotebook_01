{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'  #默认为'last'\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "from numpy import linalg\n",
    "np.set_printoptions(threshold=np.inf, precision=2, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# torch.nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'weight'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'bias'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1 = nn.Linear(2,3,bias=True)\n",
    "for n,v in l1.named_parameters():\n",
    "    n\n",
    "    v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0248,  0.5489],\n",
       "        [ 1.3520, -2.0637],\n",
       "        [-0.9140,  1.1142]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.2908, 0.9804, 0.0706])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(3,2)\n",
    "b = torch.randn(3,)\n",
    "a\n",
    "b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.nn.functional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### interpolate  \n",
    "`torch.nn.functional.interpolate(input, size=None, scale_factor=None, mode='nearest', align_corners=None)`  \n",
    "Parameters\n",
    "* input (Tensor) – the input tensor\n",
    "\n",
    "* size (python:int or Tuple[python:int] or Tuple[python:int, python:int] or Tuple[python:int, python:int, python:int]) – output spatial size.\n",
    "\n",
    "* scale_factor (python:float or Tuple[python:float]) – multiplier for spatial size. Has to match input size if it is a tuple.\n",
    "\n",
    "* mode (str) – algorithm used for upsampling: 'nearest' | 'linear' | 'bilinear' | 'bicubic' | 'trilinear' | 'area'. Default: 'nearest'\n",
    "\n",
    "* align_corners (bool, optional) – Geometrically, we consider the pixels of the input and output as squares rather than points. If set to True, the input and output tensors are aligned by the center points of their corner pixels, preserving the values at the corner pixels. If set to False, the input and output tensors are aligned by the corner points of their corner pixels, and the interpolation uses edge value padding for out-of-boundary values, making this operation independent of input size when scale_factor is kept the same. This only has an effect when mode is 'linear', 'bilinear', 'bicubic' or 'trilinear'. Default: False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 1.],\n",
       "         [2., 3.]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 1., 1.],\n",
       "         [2., 2., 3., 3.]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 1.],\n",
       "          [2., 3.]],\n",
       "\n",
       "         [[4., 5.],\n",
       "          [6., 7.]]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 1., 1.],\n",
       "          [0., 0., 1., 1.],\n",
       "          [2., 2., 3., 3.],\n",
       "          [2., 2., 3., 3.]],\n",
       "\n",
       "         [[4., 4., 5., 5.],\n",
       "          [4., 4., 5., 5.],\n",
       "          [6., 6., 7., 7.],\n",
       "          [6., 6., 7., 7.]]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_printoptions(precision=2)\n",
    "a=torch.arange(4.).reshape(1,2,2)\n",
    "a\n",
    "nn.functional.interpolate(a,scale_factor=2,mode='nearest')\n",
    "a=torch.arange(8.).reshape(1,2,2,2)\n",
    "a\n",
    "nn.functional.interpolate(a,scale_factor=2,mode='nearest')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.,  2.,  3.],\n",
       "          [ 4.,  5.,  6.],\n",
       "          [ 7.,  8.,  9.]],\n",
       "\n",
       "         [[10., 11., 12.],\n",
       "          [13., 14., 15.],\n",
       "          [16., 17., 18.]]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.00,  1.40,  1.80,  2.20,  2.60,  3.00],\n",
       "          [ 2.20,  2.60,  3.00,  3.40,  3.80,  4.20],\n",
       "          [ 3.40,  3.80,  4.20,  4.60,  5.00,  5.40],\n",
       "          [ 4.60,  5.00,  5.40,  5.80,  6.20,  6.60],\n",
       "          [ 5.80,  6.20,  6.60,  7.00,  7.40,  7.80],\n",
       "          [ 7.00,  7.40,  7.80,  8.20,  8.60,  9.00]],\n",
       "\n",
       "         [[10.00, 10.40, 10.80, 11.20, 11.60, 12.00],\n",
       "          [11.20, 11.60, 12.00, 12.40, 12.80, 13.20],\n",
       "          [12.40, 12.80, 13.20, 13.60, 14.00, 14.40],\n",
       "          [13.60, 14.00, 14.40, 14.80, 15.20, 15.60],\n",
       "          [14.80, 15.20, 15.60, 16.00, 16.40, 16.80],\n",
       "          [16.00, 16.40, 16.80, 17.20, 17.60, 18.00]]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.00,  1.25,  1.75,  2.25,  2.75,  3.00],\n",
       "          [ 1.75,  2.00,  2.50,  3.00,  3.50,  3.75],\n",
       "          [ 3.25,  3.50,  4.00,  4.50,  5.00,  5.25],\n",
       "          [ 4.75,  5.00,  5.50,  6.00,  6.50,  6.75],\n",
       "          [ 6.25,  6.50,  7.00,  7.50,  8.00,  8.25],\n",
       "          [ 7.00,  7.25,  7.75,  8.25,  8.75,  9.00]],\n",
       "\n",
       "         [[10.00, 10.25, 10.75, 11.25, 11.75, 12.00],\n",
       "          [10.75, 11.00, 11.50, 12.00, 12.50, 12.75],\n",
       "          [12.25, 12.50, 13.00, 13.50, 14.00, 14.25],\n",
       "          [13.75, 14.00, 14.50, 15.00, 15.50, 15.75],\n",
       "          [15.25, 15.50, 16.00, 16.50, 17.00, 17.25],\n",
       "          [16.00, 16.25, 16.75, 17.25, 17.75, 18.00]]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_printoptions(precision=2)\n",
    "a=torch.arange(8.).reshape(1,2,2,2)\n",
    "a=torch.arange(1,19.).reshape(1,2,3,3)\n",
    "a\n",
    "nn.functional.interpolate(a,scale_factor=2,mode='bilinear',align_corners=True)\n",
    "nn.functional.interpolate(a,scale_factor=2,mode='bilinear',align_corners=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[一文看懂align_corners](https://zhuanlan.zhihu.com/p/87572724)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### upsample(废弃，改用interpolate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# torch.sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 3.],\n",
       "        [4., 0., 5.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = torch.LongTensor([[0, 1, 1], [2, 0, 2]])\n",
    "v = torch.FloatTensor([3, 4, 5])\n",
    "torch.sparse.FloatTensor(i, v, torch.Size([2,3])).to_dense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 3.],\n",
       "        [4., 0., 5.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = torch.LongTensor([[0, 2], [1, 0], [1, 2]])\n",
    "v = torch.FloatTensor([3, 4, 5])\n",
    "torch.sparse.FloatTensor(i.t(), v, torch.Size([2, 3])).to_dense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 4]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1., 3.],\n",
       "        [5., 7.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor(indices=tensor([[2, 4]]),\n",
       "       values=tensor([[1., 3.],\n",
       "                      [5., 7.]]),\n",
       "       size=(5, 2), nnz=2, layout=torch.sparse_coo)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [1., 3.],\n",
       "        [0., 0.],\n",
       "        [5., 7.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = torch.LongTensor([[2, 4]])\n",
    "i\n",
    "v = torch.FloatTensor([[1, 3], [5, 7]])\n",
    "v\n",
    "torch.sparse.FloatTensor(i, v)\n",
    "torch.sparse.FloatTensor(i, v).to_dense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(indices=tensor([[0, 0, 0, 1, 1, 1],\n",
       "                       [0, 1, 2, 0, 1, 2]]),\n",
       "       values=tensor([ 2.0876, -0.3764,  0.4160, -0.5974, -1.8790,  1.1513]),\n",
       "       size=(2, 3), nnz=6, layout=torch.sparse_coo, requires_grad=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.0876, -0.3764,  0.4160],\n",
       "        [-0.5974, -1.8790,  1.1513]], grad_fn=<ToDenseBackward>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.1082,  0.7027],\n",
       "        [ 1.6664,  0.8173],\n",
       "        [-1.6953,  0.5092]], requires_grad=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.0686,  1.3711],\n",
       "        [-6.3424, -1.3692]], grad_fn=<SparseAddmmBackward>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor(indices=tensor([[0, 0, 0, 1, 1, 1],\n",
       "                       [0, 1, 2, 0, 1, 2]]),\n",
       "       values=tensor([ 2.8109,  2.4837, -1.1860,  2.8109,  2.4837, -1.1860]),\n",
       "       size=(2, 3), nnz=6, layout=torch.sparse_coo)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(2, 3).to_sparse().requires_grad_(True)\n",
    "a\n",
    "a.to_dense()\n",
    "# tensor(indices=tensor([[0, 0, 0, 1, 1, 1],\n",
    "#                        [0, 1, 2, 0, 1, 2]]),\n",
    "#        values=tensor([ 1.5901,  0.0183, -0.6146,  1.8061, -0.0112,  0.6302]),\n",
    "#        size=(2, 3), nnz=6, layout=torch.sparse_coo, requires_grad=True)\n",
    "\n",
    "b = torch.randn(3, 2, requires_grad=True)\n",
    "b\n",
    "# tensor([[-0.6479,  0.7874],\n",
    "#         [-1.2056,  0.5641],\n",
    "#         [-1.1716, -0.9923]], requires_grad=True)\n",
    "\n",
    "y = torch.sparse.mm(a, b)\n",
    "y\n",
    "# tensor([[-0.3323,  1.8723],\n",
    "#         [-1.8951,  0.7904]], grad_fn=<SparseAddmmBackward>)\n",
    "y.sum().backward()\n",
    "a.grad\n",
    "# tensor(indices=tensor([[0, 0, 0, 1, 1, 1],\n",
    "#                        [0, 1, 2, 0, 1, 2]]),\n",
    "#        values=tensor([ 0.1394, -0.6415, -2.1639,  0.1394, -0.6415, -2.1639]),\n",
    "#        size=(2, 3), nnz=6, layout=torch.sparse_coo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2.]]), tensor([[3., 4.]]), tensor([[5., 6.]]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.],\n",
       "        [5., 6.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1=torch.Tensor([[1,2]])\n",
    "a2=torch.Tensor([[3,4]])\n",
    "a3=torch.Tensor([[5,6]])\n",
    "a = (a1,a2,a3)\n",
    "a\n",
    "torch.cat(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# einsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.3010,  0.1340, -2.2113, -0.6608],\n",
       "        [ 0.7092,  0.0731, -1.2054, -0.3602],\n",
       "        [-0.5546, -0.0571,  0.9426,  0.2817],\n",
       "        [ 0.6613,  0.0681, -1.1240, -0.3359],\n",
       "        [ 0.6079,  0.0626, -1.0333, -0.3088]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6743,  0.2117, -0.1060],\n",
       "        [-5.9914,  2.7196, -8.2246]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.9479, -0.8942,  0.6105,  1.2177],\n",
       "         [ 5.1920, -2.0442,  3.7597,  0.2774]],\n",
       "\n",
       "        [[ 1.9755,  3.0665,  0.5966, -2.7625],\n",
       "         [-1.7776, -4.3762, -0.1269, -1.9066]],\n",
       "\n",
       "        [[ 1.1460,  1.0215, -0.8949,  1.3821],\n",
       "         [-0.1486, -1.9964,  1.4362, -0.9691]]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.5741,  0.7686, -1.5141])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9746, -1.4177, -1.3442],\n",
       "        [-0.2116,  0.5845,  0.7181],\n",
       "        [ 0.2219, -0.7531,  1.5207],\n",
       "        [-0.9117, -1.1787,  0.6000]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 5, 4])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(5)\n",
    "y = torch.randn(4)\n",
    "torch.einsum('i,j->ij', x, y)  # outer product\n",
    "# tensor([[-0.0570, -0.0286, -0.0231,  0.0197],\n",
    "#         [ 1.2616,  0.6335,  0.5113, -0.4351],\n",
    "#         [ 1.4452,  0.7257,  0.5857, -0.4984],\n",
    "#         [-0.4647, -0.2333, -0.1883,  0.1603],\n",
    "#         [-1.1130, -0.5588, -0.4510,  0.3838]])\n",
    "\n",
    "\n",
    "A = torch.randn(3,5,4)\n",
    "l = torch.randn(2,5)\n",
    "r = torch.randn(2,4)\n",
    "torch.einsum('bn,anm,bm->ba', l, A, r) # compare torch.nn.functional.bilinear\n",
    "# tensor([[-0.3430, -5.2405,  0.4494],\n",
    "#         [ 0.3311,  5.5201, -3.0356]])\n",
    "\n",
    "\n",
    "As = torch.randn(3,2,5)\n",
    "Bs = torch.randn(3,5,4)\n",
    "torch.einsum('bij,bjk->bik', As, Bs) # batch matrix multiplication\n",
    "# tensor([[[-1.0564, -1.5904,  3.2023,  3.1271],\n",
    "#          [-1.6706, -0.8097, -0.8025, -2.1183]],\n",
    "\n",
    "#         [[ 4.2239,  0.3107, -0.5756, -0.2354],\n",
    "#          [-1.4558, -0.3460,  1.5087, -0.8530]],\n",
    "\n",
    "#         [[ 2.8153,  1.8787, -4.3839, -1.2112],\n",
    "#          [ 0.3728, -2.1131,  0.0921,  0.8305]]])\n",
    "\n",
    "A = torch.randn(3, 3)\n",
    "torch.einsum('ii->i', A) # diagonal\n",
    "# tensor([-0.7825,  0.8291, -0.1936])\n",
    "\n",
    "A = torch.randn(4, 3, 3)\n",
    "torch.einsum('...ii->...i', A) # batch diagonal\n",
    "# tensor([[-1.0864,  0.7292,  0.0569],\n",
    "#         [-0.9725, -1.0270,  0.6493],\n",
    "#         [ 0.5832, -1.1716, -1.5084],\n",
    "#         [ 0.4041, -1.1690,  0.8570]])\n",
    "\n",
    "A = torch.randn(2, 3, 4, 5)\n",
    "torch.einsum('...ij->...ji', A).shape # batch permute\n",
    "# torch.Size([2, 3, 5, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11]],\n",
       "\n",
       "        [[12, 13, 14, 15],\n",
       "         [16, 17, 18, 19],\n",
       "         [20, 21, 22, 23]]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1.],\n",
       "         [1., 1.]],\n",
       "\n",
       "        [[1., 1.],\n",
       "         [1., 1.]],\n",
       "\n",
       "        [[1., 1.],\n",
       "         [1., 1.]]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 6.,  6.],\n",
       "          [ 6.,  6.]],\n",
       "\n",
       "         [[22., 22.],\n",
       "          [22., 22.]],\n",
       "\n",
       "         [[38., 38.],\n",
       "          [38., 38.]]],\n",
       "\n",
       "\n",
       "        [[[54., 54.],\n",
       "          [54., 54.]],\n",
       "\n",
       "         [[70., 70.],\n",
       "          [70., 70.]],\n",
       "\n",
       "         [[86., 86.],\n",
       "          [86., 86.]]]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 2, 2])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(24).reshape(2,3,4)\n",
    "b = torch.arange(12).reshape(3,2,2)\n",
    "b = torch.ones(3,2,2)\n",
    "a\n",
    "b\n",
    "# torch.einsum('bij,bjk', a, b）\n",
    "c = torch.einsum('ij...,jkl->ijkl', a, b)\n",
    "c\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.,  1.],\n",
       "          [ 2.,  3.],\n",
       "          [ 4.,  5.]],\n",
       "\n",
       "         [[ 6.,  7.],\n",
       "          [ 8.,  9.],\n",
       "          [10., 11.]]],\n",
       "\n",
       "\n",
       "        [[[12., 13.],\n",
       "          [14., 15.],\n",
       "          [16., 17.]],\n",
       "\n",
       "         [[18., 19.],\n",
       "          [20., 21.],\n",
       "          [22., 23.]]]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 2., 1., 2.],\n",
       "         [1., 2., 1., 2.],\n",
       "         [1., 2., 1., 2.]],\n",
       "\n",
       "        [[1., 2., 1., 2.],\n",
       "         [1., 2., 1., 2.],\n",
       "         [1., 2., 1., 2.]]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.,  2.,  1.,  2.],\n",
       "          [ 5., 10.,  5., 10.],\n",
       "          [ 9., 18.,  9., 18.]],\n",
       "\n",
       "         [[13., 26., 13., 26.],\n",
       "          [17., 34., 17., 34.],\n",
       "          [21., 42., 21., 42.]]],\n",
       "\n",
       "\n",
       "        [[[25., 50., 25., 50.],\n",
       "          [29., 58., 29., 58.],\n",
       "          [33., 66., 33., 66.]],\n",
       "\n",
       "         [[37., 74., 37., 74.],\n",
       "          [41., 82., 41., 82.],\n",
       "          [45., 90., 45., 90.]]]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 3, 4])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(24.).reshape(2,2,3,2)\n",
    "# b = torch.arange(12).reshape(3,2,2)\n",
    "b = torch.Tensor([1,2]).repeat(2, 3, 2)\n",
    "a\n",
    "b\n",
    "c = torch.einsum('bij...,bjk->bijk', a, b)\n",
    "# c = torch.einsum('ij,jk->ik', a, b)\n",
    "c\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function repeat:\n",
      "\n",
      "repeat(...) method of torch.Tensor instance\n",
      "    repeat(*sizes) -> Tensor\n",
      "    \n",
      "    Repeats this tensor along the specified dimensions.\n",
      "    \n",
      "    Unlike :meth:`~Tensor.expand`, this function copies the tensor's data.\n",
      "    \n",
      "    .. warning::\n",
      "    \n",
      "        :func:`torch.repeat` behaves differently from\n",
      "        `numpy.repeat <https://docs.scipy.org/doc/numpy/reference/generated/numpy.repeat.html>`_,\n",
      "        but is more similar to\n",
      "        `numpy.tile <https://docs.scipy.org/doc/numpy/reference/generated/numpy.tile.html>`_.\n",
      "        For the operator similar to `numpy.repeat`, see :func:`torch.repeat_interleave`.\n",
      "    \n",
      "    Args:\n",
      "        sizes (torch.Size or int...): The number of times to repeat this tensor along each\n",
      "            dimension\n",
      "    \n",
      "    Example::\n",
      "    \n",
      "        >>> x = torch.tensor([1, 2, 3])\n",
      "        >>> x.repeat(4, 2)\n",
      "        tensor([[ 1,  2,  3,  1,  2,  3],\n",
      "                [ 1,  2,  3,  1,  2,  3],\n",
      "                [ 1,  2,  3,  1,  2,  3],\n",
      "                [ 1,  2,  3,  1,  2,  3]])\n",
      "        >>> x.repeat(4, 2, 1).size()\n",
      "        torch.Size([4, 2, 3])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(a.repeat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "219.422px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
